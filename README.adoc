// Include a Table of Contents on the left hand side.
:toc: left
// ":icons: font" is needed for adminition and callout icons.
:icons: font

= Control plane database testing

See https://53.rfd.oxide.computer/[RFD 53 ("Control plane data storage requirements")] for background.

== Current status

Successfully using Terraform to provision a 3-node CockroachDB cluster on AWS, using OmniOS and https://sysmgr.org/~jclulow/tmp/cockroach.tar.gz[Joshua's CRDB binaries].

Plan (again, see RFD 53):

* Go through some basic docs:
** Tutorials, starting with https://www.cockroachlabs.com/docs/v20.1/demo-replication-and-rebalancing.html[Replication and rebalancing]
* Basic testing
** Look at 'SHOW RANGES FROM TABLE ... '
** Look at 'SHOW RANGES FROM INDEX ... '
** See queries with "SHOW QUERIES", etc.
** See performance in metrics
** Inject some failures and see what it looks like -- to the load generator as
   well as in metrics
*** graceful restarts
*** kill -9
*** hard reset OS
*** network partition
** Check on results:
*** what do the load generators see?
*** what do the server instances see?
*** what do the metrics see?
* Deeper testing
** Test cold start
** Test partition
** What happens if lots of data is written during an extended outage or partition
** Replication -- part or all of the namespace
** Backup / restore
** Scale out
** Scale down?
** Decommissioning a node (`cockroach node decommission`)
** Draining a node (`cockroach node drain`)
** Rolling upgrade
** Use "debug" commands to poke at internals
** Changefeed?  Explore for backup or other DR?
* Exercise Rust postgresql client
* Debugging known pathologies
** e.g., a range that needs to be split using https://www.cockroachlabs.com/docs/v20.1/split-at[split-at] because of load
* Lower priority:
** Go through https://www.cockroachlabs.com/docs/v20.1/performance.html[perf tuning exercises] in detail

== Usage synopsis

To deploy a cluster, you need to have:

- terraform configured using your AWS account
- an ssh key configured in AWS called "dap-terraform" OR change locals.ssh_key_name in terraform/nodes.tf to refer to your key's name
- a bunch of binaries downloaded by hand into this repo.  There's not a great way to assemble this yet, but .gitignore can tell you what they are and where they go.

**With those prerequisites in place**, you can construct the tarball to be used on each host:

[source,text]
----
$ cd vminit
$ make
----

Then upload these to the S3 bucket:

[source,text]
----
$ aws s3 cp vminit-common.tgz s3://oxide-cockroachdb-exploration/vminit-common.tgz
$ aws s3 cp vminit-cockroachdb.tgz s3://oxide-cockroachdb-exploration/vminit-cockroachdb.tgz
$ aws s3 cp vminit-mon.tgz s3://oxide-cockroachdb-exploration/vminit-mon.tgz
----

Then use terraform to deploy the cluster:

[source,text]
----
$ cd terraform
$ terraform apply
----

This will emit the public and private IPs of all the nodes in the cluster.  Note the private IP address of any of the database nodes, then log into the load generator and run:

[source,text]
----
$ ssh root@$LOADGEN_PUBLIC_IP
$ configure_cluster --host DB_PRIVATE_IP
----

== Planning notes

Will use AWS to start playing with it.

* Will use https://www.cockroachlabs.com/docs/v20.1/topology-basic-production["Basic Production"].
* Make sure to use the https://www.cockroachlabs.com/docs/v20.1/cockroach-start#locality[locality] flag if we end up using different AZs.

In terms of https://www.cockroachlabs.com/docs/v20.1/recommended-production-settings#software[host operating system]:

> We recommend running a glibc-based Linux distribution and Linux kernel version from the last 5 years, such as Ubuntu, Red Hat Enterprise Linux (RHEL), CentOS, or Container-Optimized OS.

We'll try illumos to see how it goes.

https://www.cockroachlabs.com/docs/v20.1/recommended-production-settings#basic-hardware-recommendations[Basic hardware recommendations]: for each vCPU, it's recommended to expect 4 GiB of RAM, 60 GiB of storage, 500 disk IOPS, and 30 MBps of disk I/O.  Recommend at least 2 vCPUS and better would be 4 vCPUs per node.  Price out a 4-vCPU node?  Avoid "burstable" or "shared-core".  Use "m" (general-purpose) or "c" ("compute-optimized").  Recommend "c5d" for use with EBS using SSD instances.

If we want to save cost significantly, we should shut down these instances when we don't actively need them to be running.  If we use "c5d", we'll probably lose local storage.  This would be a good reason to use "c5" with an EBS volume.  The perf will presumably be worse, but presumably not pathologically so, and we're more interested in ballpark / pathological figures than absolute best perf.  We probably don't need fantastic performance out of the gate to do basic fault testing, but we also don't want to see pathological behavior (e.g., due to starvation).

Adam points out that illumos won't currently run on "c5" or other generations that require ENA networking, so we should stick with "c4" for now.

https://www.cockroachlabs.com/docs/v20.1/recommended-production-settings#connection-pooling[Recommended connection pool size:] 2 * core count + ssd count.  It's unclear if this is a server-side figure or a client-side figure or what?

Considerations for later:

- file descriptor limit
- cache size

Load generators: There are several https://www.cockroachlabs.com/docs/v20.1/cockroach-workload.html[workload options].  Note that the workloads have a `--tolerate-errors` option.  Most promising seem like "bank", "kv", "tpcc", "ycsb".

In terms of images, it looks like https://omniosce.org/setup/aws[AWS AMI images are available for recent versions of OmniOS].

=== Calculating cost on AWS

Requirements:

* Use "c4large" for db and load generators (see above).
* Grafana recommends 256 MiB memory + 1 CPU.
* Prometheus seems to want 3 GiB of memory.
* Do this all in "us-west-2" (cheaper than some other regions)

Let's put Grafana + Prometheus in a single t3.medium instance.

https://calculator.aws/#/estimate?id=16e6ed9a0102c9e24880a0175edaa9eef88ac8c9[Estimate:]

* 6 "c4large" instances (3xCRDB + 3xload generators) with 60 GiB "gp2" storage each: $474 / month
* 1 "t3.medium" instance (Prometheus + Grafana): $36 / month

Total: $510 / month.  If we only use it for, say, 10 hours a week, that's only $30 / month.

== Known issues

* Before you've initialized the CRDB cluster, if you go to the adminui, you get
a very blank 404 page
* CockroachDB crashes pretty roughly when the clocks go out of sync.

== General notes

CockroachDB recently changed the default from RocksDB to PebbleDB, despite the documentation (even for the build that I'm using) not having been updated to reflect that.

To make terraform forget about something: `terraform state rm aws_instance.db[0]`

To list _all_ instances created with a particular key:

[source,text]
----
aws ec2 describe-instances --filters 'Name=key-name,Values=dap-terraform' --query 'Reservations[*].Instances[*].{Name:Tags[?Key=='"'"'Name'"'"']|[0].Value,InstanceId:InstanceId,StateName:State.Name,Internal:PrivateIpAddress,Public:PublicIpAddress}' --output json  | json -a | json -ga InstanceId StateName Internal Public Name | column -t | sort -k7n
----

To list instances created for this exploration:

[source,text]
----
aws ec2 describe-instances --filters 'Name=tag:Project,Values=crdb_exploration' --query 'Reservations[*].Instances[*].{Name:Tags[?Key=='"'"'Name'"'"']|[0].Value,InstanceId:InstanceId,StateName:State.Name,Internal:PrivateIpAddress,Public:PublicIpAddress}' --output json  | json -a | json -ga InstanceId StateName Internal Public Name | column -t | sort -k5
----

To stop the instances:

[source,text]
----
aws ec2 describe-instances --filters 'Name=tag:Project,Values=crdb_exploration' 'Name=instance-state-name,Values=running' --query 'Reservations[*].Instances[*].{Instance:InstanceId}' | json -a | json -ga Instance | xargs -t aws ec2 stop-instances --instance-ids
----

To start the instances:

[source,text]
----
aws ec2 describe-instances --filters 'Name=tag:Project,Values=crdb_exploration' 'Name=instance-state-name,Values=stopped' --query 'Reservations[*].Instances[*].{Instance:InstanceId}' | json -a | json -ga Instance | xargs -t aws ec2 start-instances --instance-ids
----

== For further digging

* https://www.cockroachlabs.com/docs/v20.1/cluster-setup-troubleshooting#capacity-planning-issues[Capacity planning issues]
* https://www.cockroachlabs.com/docs/v20.1/cluster-setup-troubleshooting#memory-issues[Memory issues].

== Caveats

* Currently https://www.cockroachlabs.com/docs/v20.1/recommended-production-settings#storage[limited to 4 TiB of storage per node].
* https://www.cockroachlabs.com/docs/v20.1/recommended-production-settings#load-balancing[They expect clients to load balance for performance and reliability.]
* Regarding https://news.ycombinator.com/item?id=20098942[use of something like ZFS snapshots for backup].
* I tried activating statement diagnostics for an UPSERT that one of the workloads runs to see what that does.  This produced a bundle that was 23 bytes (0 bytes downloaded, for some reason).  This may have been a known bug (see raw notes file) but I'm not sure.
* https://www.cockroachlabs.com/docs/v20.1/known-limitations.html#cold-starts-of-large-clusters-may-require-manual-intervention[Ugly looking bug around cluster startup]
* https://www.cockroachlabs.com/docs/v20.1/rename-table#table-renaming-considerations[Table renaming is not transactional]

Regarding the Terraform deployment: note that we sometimes hit:
https://github.com/terraform-providers/terraform-provider-aws/issues/12533
Retrying `terraform apply` has worked around the issue.

== References

* https://www.cockroachlabs.com/docs/stable/deploy-cockroachdb-on-aws.html[CockroachDB on AWS]
* https://kbild.ch/blog/2019-02-18-awsprometheus/[Prometheus on AWS].
* https://www.slideshare.net/mitsuhirotanda/prometheus-on-aws-63736540[Prometheus on AWS] (slide deck)
* https://github.com/oxidecomputer/storage-exploration[Adam's Terraform config for storage exploration]
* https://aws.amazon.com/ec2/instance-types/[AWS Instance Types]
* https://github.com/oxidecomputer/confomat-oxide[Josh's confomat stuff]
* http://wiki.omniosce.org/GeneralAdministration[OmniOS administration]
* https://console.aws.amazon.com/ec2/v2/home?region=us-west-2#Instances:sort=instanceId[AWS EC2 console (us-west-2)]
* https://www.terraform.io/docs/cli-index.html[Terraform CLI docs]
* https://docs.aws.amazon.com/cli/latest/reference/ec2/describe-instances.html[AWS describe-instances CLI]
* https://github.com/prometheus/haproxy_exporter#official-prometheus-exporter[haproxy Prometheus support]
